2024-10-01 15:56:40 INFO  Starting evaluation job
2024-10-01 15:56:40 INFO  Extra arguments that will be passed to the underlying script: ++split=test ++prompt_template=llama3-instruct
────────────────────────────── Entering Experiment eval with id: eval_1727783800 ───────────────────────────────
[15:56:40] INFO     Launching task with command echo "Evaluating benchmark human-eval" && python -m  eval.py:166
                    nemo_skills.inference.generate     ++dataset=human-eval     ++split=test                    
                    ++output_file=/workspace/test-human-eval-local/eval-results/human-eval/output-gr            
                    eedy.jsonl      ++split=test ++prompt_template=llama3-instruct                              
                    ++server.server_type=vllm  && python -m nemo_skills.evaluation.evaluate_results             
                    ++input_files=/workspace/test-human-eval-local/eval-results/human-eval/output-gr            
                    eedy.jsonl ++eval_type=code ++eval_config.dataset=humaneval                                 
[15:56:40] Launching task nemo-run for experiment eval                                         experiment.py:601
[15:56:41] INFO     Pulling container image: igitman/nemo-skills-sandbox:0.4.1 (this may take a    docker.py:113
                    while)                                                                                      
[15:56:43] INFO     Pulling container image: igitman/nemo-skills:0.4.1 (this may take a while)     docker.py:113
[15:56:44] INFO     Pulling container image: igitman/nemo-skills-vllm:0.4.1 (this may take a       docker.py:113
                    while)                                                                                      
[15:56:46] INFO     Launched app: docker_persistent://nemo_run/nemo-run-z7lj276glksd2            launcher.py:105
[15:56:47] INFO     AppStatus:                                                                   launcher.py:108
                        State: RUNNING                                                                          
                        Num Restarts: -1                                                                        
                        Roles:                                                                                  
                     *nemo-run-0[0]:RUNNING                                                                     
                     *nemo-run-1[0]:RUNNING                                                                     
                     *nemo-run-2[0]:RUNNING                                                                     
                        Msg: <NONE>                                                                             
                        Structured Error Msg: <NONE>                                                            
                        UI URL: None                                                                            
                                                                                                                
           INFO     Waiting for job nemo-run-z7lj276glksd2 to finish [log=True]...               launcher.py:126
nemo-run-1/0 Waiting for the server to start
nemo-run-1/0 Evaluating benchmark human-eval
nemo-run-2/0 Checking for script in /app/prestart.sh
nemo-run-2/0 Running script /app/prestart.sh
nemo-run-0/0 
nemo-run-2/0 Running inside /app/prestart.sh, you could add migrations to this file, e.g.:
nemo-run-0/0 =============
nemo-run-2/0 
nemo-run-0/0 == PyTorch ==
nemo-run-2/0 #! /usr/bin/env sh
nemo-run-0/0 =============
nemo-run-2/0 
nemo-run-0/0 
nemo-run-2/0 # Let the DB start
nemo-run-0/0 NVIDIA Release 24.03 (build 85286408)
nemo-run-2/0 sleep 10;
nemo-run-0/0 PyTorch Version 2.3.0a0+40ec155e58
nemo-run-2/0 # Run migrations
nemo-run-0/0 Container image Copyright (c) 2024, NVIDIA CORPORATION & AFFILIATES. All rights reserved.
nemo-run-2/0 alembic upgrade head
nemo-run-0/0 Copyright (c) 2014-2024 Facebook Inc.
nemo-run-2/0 
nemo-run-0/0 Copyright (c) 2011-2014 Idiap Research Institute (Ronan Collobert)
nemo-run-2/0 /usr/lib/python3/dist-packages/supervisor/options.py:474: UserWarning: Supervisord is running as root and it is searching for its configuration file in default locations (including its current working directory); you probably want to specify a "-c" argument specifying an absolute path to a configuration file for improved security.
nemo-run-0/0 Copyright (c) 2012-2014 Deepmind Technologies    (Koray Kavukcuoglu)
nemo-run-2/0   self.warnings.warn(
nemo-run-0/0 Copyright (c) 2011-2012 NEC Laboratories America (Koray Kavukcuoglu)
nemo-run-2/0 2024-10-01 11:56:47,078 CRIT Supervisor is running as root.  Privileges were not dropped because no user is specified in the config file.  If you intend to run as root, you can set user=root in the config file to avoid this message.
nemo-run-0/0 Copyright (c) 2011-2013 NYU                      (Clement Farabet)
nemo-run-2/0 2024-10-01 11:56:47,078 INFO Included extra file "/etc/supervisor/conf.d/supervisord.conf" during parsing
nemo-run-0/0 Copyright (c) 2006-2010 NEC Laboratories America (Ronan Collobert, Leon Bottou, Iain Melvin, Jason Weston)
nemo-run-2/0 2024-10-01 11:56:47,080 INFO RPC interface 'supervisor' initialized
nemo-run-0/0 Copyright (c) 2006      Idiap Research Institute (Samy Bengio)
nemo-run-2/0 2024-10-01 11:56:47,080 CRIT Server 'unix_http_server' running without any HTTP authentication checking
nemo-run-0/0 Copyright (c) 2001-2004 Idiap Research Institute (Ronan Collobert, Samy Bengio, Johnny Mariethoz)
nemo-run-2/0 2024-10-01 11:56:47,080 INFO supervisord started with pid 12
nemo-run-0/0 Copyright (c) 2015      Google Inc.
nemo-run-0/0 Copyright (c) 2015      Yangqing Jia
nemo-run-0/0 Copyright (c) 2013-2016 The Caffe contributors
nemo-run-0/0 All rights reserved.
nemo-run-0/0 
nemo-run-0/0 Various files include modifications (c) NVIDIA CORPORATION & AFFILIATES.  All rights reserved.
nemo-run-0/0 
nemo-run-0/0 This container image and its contents are governed by the NVIDIA Deep Learning Container License.
nemo-run-0/0 By pulling and using the container, you accept the terms and conditions of this license:
nemo-run-0/0 https://developer.nvidia.com/ngc/nvidia-deep-learning-container-license
nemo-run-0/0 
nemo-run-0/0 Tue Oct  1 11:56:46 2024       
nemo-run-0/0 +-----------------------------------------------------------------------------------------+
nemo-run-0/0 | NVIDIA-SMI 560.35.03              Driver Version: 560.35.03      CUDA Version: 12.6     |
nemo-run-0/0 |-----------------------------------------+------------------------+----------------------+
nemo-run-0/0 | GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |
nemo-run-0/0 | Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |
nemo-run-0/0 |                                         |                        |               MIG M. |
nemo-run-0/0 |=========================================+========================+======================|
nemo-run-0/0 |   0  NVIDIA RTX A6000               Off |   00000000:17:00.0 Off |                  Off |
nemo-run-0/0 | 30%   47C    P5             22W /  300W |      24MiB /  49140MiB |      1%      Default |
nemo-run-0/0 |                                         |                        |                  N/A |
nemo-run-0/0 +-----------------------------------------+------------------------+----------------------+
nemo-run-0/0                                                                                          
nemo-run-0/0 +-----------------------------------------------------------------------------------------+
nemo-run-0/0 | Processes:                                                                              |
nemo-run-0/0 |  GPU   GI   CI        PID   Type   Process name                              GPU Memory |
nemo-run-0/0 |        ID   ID                                                               Usage      |
nemo-run-0/0 |=========================================================================================|
nemo-run-0/0 +-----------------------------------------------------------------------------------------+
nemo-run-0/0 Deploying model meta-llama/Llama-3.1-8B-Instruct
nemo-run-0/0 Starting OpenAI Server
nemo-run-1/0 2024-10-01 11:56:47 INFO  Config used: GenerateSolutionsConfig(output_file='/workspace/test-human-eval-local/eval-results/human-eval/output-greedy.jsonl', server={'server_type': 'vllm'}, sandbox={}, prompt_template='llama3-instruct', prompt_config=None, examples_type=None, inference=InferenceConfig(temperature=0.0, top_k=0, top_p=0.95, random_seed=0, tokens_to_generate=2048, repetition_penalty=1.0), dataset='human-eval', split='test', input_file=PosixPath('/nemo_run/code/nemo_skills/dataset/human-eval/test.jsonl'), batch_size=128, max_samples=-1, skip_filled=False, offset=0, generation_key='generation', dry_run=False, code_execution=False)
nemo-run-1/0 2024-10-01 11:56:47 INFO  HTTP Request: GET http://127.0.0.1:5000/v1/models "HTTP/1.1 404 Not Found"
nemo-run-1/0 Error executing job with overrides: ['++dataset=human-eval', '++split=test', '++output_file=/workspace/test-human-eval-local/eval-results/human-eval/output-greedy.jsonl', '++split=test', '++prompt_template=llama3-instruct', '++server.server_type=vllm']
nemo-run-1/0 Traceback (most recent call last):
nemo-run-1/0   File "/nemo_run/code/nemo_skills/inference/generate.py", line 117, in generate
nemo-run-1/0     llm = get_model(**cfg.server)
nemo-run-1/0   File "/nemo_run/code/nemo_skills/inference/server/model.py", line 573, in get_model
nemo-run-1/0     return model_class(**kwargs)
nemo-run-1/0   File "/nemo_run/code/nemo_skills/inference/server/model.py", line 448, in __init__
nemo-run-1/0     self.model_name_server = self.get_model_name_from_server()
nemo-run-1/0   File "/nemo_run/code/nemo_skills/inference/server/model.py", line 557, in get_model_name_from_server
nemo-run-1/0     model_list = self.oai_client.models.list()
nemo-run-1/0   File "/usr/local/lib/python3.10/site-packages/openai/resources/models.py", line 91, in list
nemo-run-1/0     return self._get_api_list(
nemo-run-1/0   File "/usr/local/lib/python3.10/site-packages/openai/_base_client.py", line 1317, in get_api_list
nemo-run-1/0     return self._request_api_list(model, page, opts)
nemo-run-1/0   File "/usr/local/lib/python3.10/site-packages/openai/_base_client.py", line 1168, in _request_api_list
nemo-run-1/0     return self.request(page, options, stream=False)
nemo-run-1/0   File "/usr/local/lib/python3.10/site-packages/openai/_base_client.py", line 945, in request
nemo-run-1/0     return self._request(
nemo-run-1/0   File "/usr/local/lib/python3.10/site-packages/openai/_base_client.py", line 1049, in _request
nemo-run-1/0     raise self._make_status_error_from_response(err.response) from None
nemo-run-1/0 openai.NotFoundError: 404 page not found
nemo-run-1/0 
nemo-run-1/0 Set the environment variable HYDRA_FULL_ERROR=1 for a complete stack trace.
nemo-run-2/0 2024-10-01 11:56:48,083 INFO spawned: 'quit_on_failure' with pid 13
nemo-run-2/0 2024-10-01 11:56:48,086 INFO spawned: 'nginx' with pid 14
nemo-run-2/0 2024-10-01 11:56:48,088 INFO spawned: 'uwsgi' with pid 15
nemo-run-2/0 2024-10-01 11:56:48,091 INFO success: nginx entered RUNNING state, process has stayed up for > than 0 seconds (startsecs)
nemo-run-2/0 2024-10-01 11:56:48,091 INFO success: uwsgi entered RUNNING state, process has stayed up for > than 0 seconds (startsecs)
nemo-run-2/0 [uWSGI] getting INI configuration from /app/uwsgi.ini
nemo-run-2/0 [uWSGI] getting INI configuration from /etc/uwsgi/uwsgi.ini
nemo-run-2/0 
nemo-run-2/0 ;uWSGI instance configuration
nemo-run-2/0 [uwsgi]
nemo-run-2/0 ini = /app/uwsgi.ini
nemo-run-2/0 module = main
nemo-run-2/0 callable = app
nemo-run-2/0 processes = 240
nemo-run-2/0 cheaper = 24
nemo-run-2/0 ini = /etc/uwsgi/uwsgi.ini
nemo-run-2/0 socket = /tmp/uwsgi.sock
nemo-run-2/0 chown-socket = nginx:nginx
nemo-run-2/0 chmod-socket = 664
nemo-run-2/0 hook-master-start = unix_signal:15 gracefully_kill_them_all
nemo-run-2/0 need-app = true
nemo-run-2/0 die-on-term = true
nemo-run-2/0 show-config = true
nemo-run-2/0 ;end of configuration
nemo-run-2/0 
nemo-run-2/0 *** Starting uWSGI 2.0.26 (64bit) on [Tue Oct  1 11:56:48 2024] ***
nemo-run-2/0 compiled with version: 10.2.1 20210110 on 23 September 2024 00:25:14
nemo-run-2/0 os: Linux-6.8.0-45-generic #45~22.04.1-Ubuntu SMP PREEMPT_DYNAMIC Wed Sep 11 15:25:05 UTC 2
nemo-run-2/0 nodename: nemo-run-2
nemo-run-2/0 machine: x86_64
nemo-run-2/0 clock source: unix
nemo-run-2/0 pcre jit disabled
nemo-run-2/0 detected number of CPU cores: 28
nemo-run-2/0 current working directory: /nemo_run/code
nemo-run-2/0 detected binary path: /usr/local/bin/uwsgi
nemo-run-2/0 your memory page size is 4096 bytes
nemo-run-2/0 detected max file descriptor number: 1048576
nemo-run-2/0 lock engine: pthread robust mutexes
nemo-run-2/0 thunder lock: disabled (you can enable it with --thunder-lock)
nemo-run-2/0 uwsgi socket 0 bound to UNIX address /tmp/uwsgi.sock fd 3
nemo-run-2/0 uWSGI running as root, you can use --uid/--gid/--chroot options
nemo-run-2/0 *** WARNING: you are running uWSGI as root !!! (use the --uid flag) *** 
nemo-run-2/0 Python version: 3.10.15 (main, Sep 12 2024, 21:08:59) [GCC 10.2.1 20210110]
nemo-run-2/0 *** Python threads support is disabled. You can enable it with --enable-threads ***
nemo-run-2/0 Python main interpreter initialized at 0x625851705dd0
nemo-run-2/0 uWSGI running as root, you can use --uid/--gid/--chroot options
nemo-run-2/0 *** WARNING: you are running uWSGI as root !!! (use the --uid flag) *** 
nemo-run-2/0 your server socket listen backlog is limited to 100 connections
nemo-run-2/0 your mercy for graceful operations on workers is 60 seconds
nemo-run-2/0 mapped 17573720 bytes (17161 KB) for 240 cores
nemo-run-0/0 /usr/local/lib/python3.10/dist-packages/transformers/utils/hub.py:127: FutureWarning: Using `TRANSFORMERS_CACHE` is deprecated and will be removed in v5 of Transformers. Use `HF_HOME` instead.
nemo-run-0/0   warnings.warn(
nemo-run-2/0 *** Operational MODE: preforking ***
nemo-run-0/0 WARNING 10-01 11:56:48 cuda.py:22] You are using a deprecated `pynvml` package. Please install `nvidia-ml-py` instead, and make sure to uninstall `pynvml`. When both of them are installed, `pynvml` will take precedence and cause errors. See https://pypi.org/project/pynvml for more information.
nemo-run-2/0 WSGI app 0 (mountpoint='') ready in 0 seconds on interpreter 0x625851705dd0 pid: 15 (default app)
nemo-run-2/0 uWSGI running as root, you can use --uid/--gid/--chroot options
nemo-run-2/0 *** WARNING: you are running uWSGI as root !!! (use the --uid flag) *** 
nemo-run-2/0 *** uWSGI is running in multiple interpreter mode ***
nemo-run-2/0 spawned uWSGI master process (pid: 15)
nemo-run-2/0 spawned uWSGI worker 1 (pid: 17, cores: 1)
nemo-run-2/0 spawned uWSGI worker 2 (pid: 18, cores: 1)
nemo-run-2/0 spawned uWSGI worker 3 (pid: 19, cores: 1)
nemo-run-2/0 spawned uWSGI worker 4 (pid: 20, cores: 1)
nemo-run-2/0 spawned uWSGI worker 5 (pid: 21, cores: 1)
nemo-run-2/0 spawned uWSGI worker 6 (pid: 22, cores: 1)
nemo-run-2/0 spawned uWSGI worker 7 (pid: 23, cores: 1)
nemo-run-2/0 spawned uWSGI worker 8 (pid: 24, cores: 1)
nemo-run-2/0 spawned uWSGI worker 9 (pid: 25, cores: 1)
nemo-run-2/0 spawned uWSGI worker 10 (pid: 26, cores: 1)
nemo-run-2/0 spawned uWSGI worker 11 (pid: 27, cores: 1)
nemo-run-2/0 spawned uWSGI worker 12 (pid: 28, cores: 1)
nemo-run-2/0 spawned uWSGI worker 13 (pid: 29, cores: 1)
nemo-run-2/0 spawned uWSGI worker 14 (pid: 30, cores: 1)
nemo-run-2/0 spawned uWSGI worker 15 (pid: 31, cores: 1)
nemo-run-2/0 spawned uWSGI worker 16 (pid: 32, cores: 1)
nemo-run-2/0 spawned uWSGI worker 17 (pid: 33, cores: 1)
nemo-run-2/0 spawned uWSGI worker 18 (pid: 34, cores: 1)
nemo-run-2/0 spawned uWSGI worker 19 (pid: 35, cores: 1)
nemo-run-2/0 spawned uWSGI worker 20 (pid: 36, cores: 1)
nemo-run-2/0 spawned uWSGI worker 21 (pid: 37, cores: 1)
nemo-run-2/0 spawned uWSGI worker 22 (pid: 38, cores: 1)
nemo-run-2/0 spawned uWSGI worker 23 (pid: 39, cores: 1)
nemo-run-2/0 spawned uWSGI worker 24 (pid: 40, cores: 1)
nemo-run-2/0 running "unix_signal:15 gracefully_kill_them_all" (master-start)...
[15:56:49] INFO     Job nemo-run-z7lj276glksd2 finished: SUCCEEDED                               launcher.py:156
───────────────────────────────── Done waiting for Experiment eval_1727783800 ──────────────────────────────────

Experiment Status for eval_1727783800

Task 0: nemo-run
- Status: SUCCEEDED
- Executor: DockerExecutor
- Job id: nemo-run-z7lj276glksd2
- Local Directory: /home/aayrapetyan/.nemo_run/experiments/eval/eval_1727783800/nemo-run

                                                                                                                
# The experiment was run with the following tasks: ['nemo-run']                                                 
# You can inspect and reconstruct this experiment at a later point in time using:                               
experiment = run.Experiment.from_id("eval_1727783800")                                                          
experiment.status() # Gets the overall status                                                                   
experiment.logs("nemo-run") # Gets the log for the provided task                                                
experiment.cancel("nemo-run") # Cancels the provided task if still running                                      
                                                                                                                
                                                                                                                
# You can inspect this experiment at a later point in time using the CLI as well:                               
nemo experiment status eval_1727783800                                                                          
nemo experiment logs eval_1727783800 0                                                                          
nemo experiment cancel eval_1727783800 0                                                                        
                                                                                                                
