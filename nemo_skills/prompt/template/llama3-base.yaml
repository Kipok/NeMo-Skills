# Prompt specification for Llama3-base model

# these tokens are always used to construct a prompt like this
#
#   single-turn:
#     <bos_token><system_begin>{system}<system_end><user_begin>{user}<user_end><assistant_begin>{generation}
#   multi-turn:
#     <bos_token><system_begin>{system}<system_end><user_begin>{user1}<user_end><assistant_begin>{assistant1}<assistant_end>...
#     <user_begin>{userN}<user_end><assistant_begin>{generation}

bos_token: "<|begin_of_text|>"

system_begin: ""
system_end: ""

user_begin: ""
user_end: ""

assistant_begin: ""
assistant_end: ""

# by default we separate few shot examples with 6 newlines, so using it to stop
stop_phrases: ["\n\n\n\n\n\n"]
